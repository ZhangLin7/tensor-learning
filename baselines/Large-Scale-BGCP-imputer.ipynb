{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "---\n",
    "\n",
    "**Bayesian Gaussian CP decomposition** (or **BGCP** for short) is a type of Bayesian tensor decomposition that achieves state-of-the-art results on challenging the missing data imputation problem. In the following, we will discuss:\n",
    "\n",
    "- What the Bayesian Gaussian CP decomposition is.\n",
    "\n",
    "- How to implement BGCP mainly using Python `numpy` with high efficiency.\n",
    "\n",
    "- How to make imputations with real-world spatiotemporal datasets.\n",
    "\n",
    "If you want to understand BGCP and its modeling tricks in detail, our paper is for you:\n",
    "\n",
    "> Xinyu Chen, Zhaocheng He, Lijun Sun (2019). **A Bayesian tensor decomposition approach for spatiotemporal traffic data imputation**. Transportation Research Part C: Emerging Technologies, 98: 73-84.\n",
    "\n",
    "## Quick Run\n",
    "\n",
    "This notebook is publicly available at [https://github.com/xinychen/tensor-learning](https://github.com/xinychen/tensor-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary dependencies. We will make use of `numpy` and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:05.986620Z",
     "start_time": "2020-11-07T08:24:05.436593Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal as mvnrnd\n",
    "from scipy.stats import wishart\n",
    "from numpy.random import normal as normrnd\n",
    "from scipy.linalg import khatri_rao as kr_prod\n",
    "from numpy.linalg import inv as inv\n",
    "from numpy.linalg import solve as solve\n",
    "from numpy.linalg import cholesky as cholesky_lower\n",
    "from scipy.linalg import cholesky as cholesky_upper\n",
    "from scipy.linalg import solve_triangular as solve_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:06.474590Z",
     "start_time": "2020-11-07T08:24:06.462593Z"
    }
   },
   "outputs": [],
   "source": [
    "def mvnrnd_pre(mu, Lambda):\n",
    "    src = normrnd(size = (mu.shape[0],))\n",
    "    return solve_ut(cholesky_upper(Lambda, overwrite_a = True, check_finite = False), \n",
    "                    src, lower = False, check_finite = False, overwrite_b = True) + mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) CP decomposition\n",
    "\n",
    "#### CP Combination (`cp_combine`)\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "The CP decomposition factorizes a tensor into a sum of outer products of vectors. For example, for a third-order tensor $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$, the CP decomposition can be written as\n",
    "\n",
    "$$\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s},$$\n",
    "or element-wise,\n",
    "\n",
    "$$\\hat{y}_{ijt}=\\sum_{s=1}^{r}u_{is}v_{js}x_{ts},\\forall (i,j,t),$$\n",
    "where vectors $\\boldsymbol{u}_{s}\\in\\mathbb{R}^{m},\\boldsymbol{v}_{s}\\in\\mathbb{R}^{n},\\boldsymbol{x}_{s}\\in\\mathbb{R}^{f}$ are columns of factor matrices $U\\in\\mathbb{R}^{m\\times r},V\\in\\mathbb{R}^{n\\times r},X\\in\\mathbb{R}^{f\\times r}$, respectively. The symbol $\\circ$ denotes vector outer product.\n",
    "\n",
    "- **Example**:\n",
    "\n",
    "Given matrices $U=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{2\\times 2}$, $V=\\left[ \\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{3\\times 2}$ and $X=\\left[ \\begin{array}{cc} 1 & 5 \\\\ 2 & 6 \\\\ 3 & 7 \\\\ 4 & 8 \\\\ \\end{array} \\right]\\in\\mathbb{R}^{4\\times 2}$, then if $\\hat{\\mathcal{Y}}=\\sum_{s=1}^{r}\\boldsymbol{u}_{s}\\circ\\boldsymbol{v}_{s}\\circ\\boldsymbol{x}_{s}$, then, we have\n",
    "\n",
    "$$\\hat{Y}_1=\\hat{\\mathcal{Y}}(:,:,1)=\\left[ \\begin{array}{ccc} 31 & 42 & 65 \\\\ 63 & 86 & 135 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_2=\\hat{\\mathcal{Y}}(:,:,2)=\\left[ \\begin{array}{ccc} 38 & 52 & 82 \\\\ 78 & 108 & 174 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_3=\\hat{\\mathcal{Y}}(:,:,3)=\\left[ \\begin{array}{ccc} 45 & 62 & 99 \\\\ 93 & 130 & 213 \\\\ \\end{array} \\right],$$\n",
    "$$\\hat{Y}_4=\\hat{\\mathcal{Y}}(:,:,4)=\\left[ \\begin{array}{ccc} 52 & 72 & 116 \\\\ 108 & 152 & 252 \\\\ \\end{array} \\right].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:09.000592Z",
     "start_time": "2020-11-07T08:24:08.996592Z"
    }
   },
   "outputs": [],
   "source": [
    "def cp_combine(var):\n",
    "    return np.einsum('is, js, ts -> ijt', var[0], var[1], var[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:09.871619Z",
     "start_time": "2020-11-07T08:24:09.861634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 31  38  45  52]\n",
      "  [ 42  52  62  72]\n",
      "  [ 65  82  99 116]]\n",
      "\n",
      " [[ 63  78  93 108]\n",
      "  [ 86 108 130 152]\n",
      "  [135 174 213 252]]]\n",
      "\n",
      "tensor size:\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "factor = [np.array([[1, 2], [3, 4]]), np.array([[1, 3], [2, 4], [5, 6]]), \n",
    "          np.array([[1, 5], [2, 6], [3, 7], [4, 8]])]\n",
    "print(cp_combine(factor))\n",
    "print()\n",
    "print('tensor size:')\n",
    "print(cp_combine(factor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Tensor Unfolding (`ten2mat`)\n",
    "\n",
    "Using numpy reshape to perform 3rd rank tensor unfold operation. [[**link**](https://stackoverflow.com/questions/49970141/using-numpy-reshape-to-perform-3rd-rank-tensor-unfold-operation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:12.160591Z",
     "start_time": "2020-11-07T08:24:12.143592Z"
    }
   },
   "outputs": [],
   "source": [
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:12.962621Z",
     "start_time": "2020-11-07T08:24:12.948592Z"
    }
   },
   "outputs": [],
   "source": [
    "def mat2ten(mat, dim, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(dim.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(dim[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Computing Covariance Matrix (`cov_mat`)\n",
    "\n",
    "For any matrix $X\\in\\mathbb{R}^{m\\times n}$, `cov_mat` can return a $n\\times n$ covariance matrix for special use in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:14.820592Z",
     "start_time": "2020-11-07T08:24:14.805590Z"
    }
   },
   "outputs": [],
   "source": [
    "def cov_mat(mat, mat_bar):\n",
    "    mat = mat - mat_bar\n",
    "    return mat.T @ mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Gaussian CP decomposition (BGCP)\n",
    "\n",
    "### 1) Model Description\n",
    "\n",
    "#### Gaussian assumption\n",
    "\n",
    "Given a matrix $\\mathcal{Y}\\in\\mathbb{R}^{m\\times n\\times f}$ which suffers from missing values, then the factorization can be applied to reconstruct the missing values within $\\mathcal{Y}$ by\n",
    "\n",
    "$$y_{ijt}\\sim\\mathcal{N}\\left(\\sum_{s=1}^{r}u_{is} v_{js} x_{ts},\\tau^{-1}\\right),\\forall (i,j,t),$$\n",
    "where vectors $\\boldsymbol{u}_{s}\\in\\mathbb{R}^{m},\\boldsymbol{v}_{s}\\in\\mathbb{R}^{n},\\boldsymbol{x}_{s}\\in\\mathbb{R}^{f}$ are columns of latent factor matrices, and $u_{is},v_{js},x_{ts}$ are their elements. The precision term $\\tau$ is an inverse of Gaussian variance.\n",
    "\n",
    "#### Bayesian framework\n",
    "\n",
    "Based on the Gaussian assumption over tensor elements $y_{ijt},(i,j,t)\\in\\Omega$ (where $\\Omega$ is a index set indicating observed tensor elements), the conjugate priors of model parameters (i.e., latent factors and precision term) and hyperparameters are given as\n",
    "\n",
    "$$\\boldsymbol{u}_{i}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{u},\\Lambda_{u}^{-1}\\right),\\forall i,$$\n",
    "$$\\boldsymbol{v}_{j}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{v},\\Lambda_{v}^{-1}\\right),\\forall j,$$\n",
    "$$\\boldsymbol{x}_{t}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{x},\\Lambda_{x}^{-1}\\right),\\forall t,$$\n",
    "$$\\tau\\sim\\text{Gamma}\\left(a_0,b_0\\right),$$\n",
    "$$\\boldsymbol{\\mu}_{u}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_0,\\left(\\beta_0\\Lambda_u\\right)^{-1}\\right),\\Lambda_u\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right),$$\n",
    "$$\\boldsymbol{\\mu}_{v}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_0,\\left(\\beta_0\\Lambda_v\\right)^{-1}\\right),\\Lambda_v\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right),$$\n",
    "$$\\boldsymbol{\\mu}_{x}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_0,\\left(\\beta_0\\Lambda_x\\right)^{-1}\\right),\\Lambda_x\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Posterior Inference\n",
    "\n",
    "In the following, we will apply Gibbs sampling to implement our Bayesian inference for the matrix factorization task.\n",
    "\n",
    "#### - Sampling latent factors $\\boldsymbol{u}_{i},i\\in\\left\\{1,2,...,m\\right\\}$\n",
    "\n",
    "Draw $\\boldsymbol{u}_{i}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_i^{*},(\\Lambda_{i}^{*})^{-1}\\right)$ with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{i}^{*}=\\left(\\Lambda_{i}^{*}\\right)^{-1}\\left\\{\\tau\\sum_{j,t:(i,j,t)\\in\\Omega}y_{ijt}\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)+\\Lambda_u\\boldsymbol{\\mu}_u\\right\\},$$\n",
    "\n",
    "$$\\Lambda_{i}^{*}=\\tau\\sum_{j,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)\\left(\\boldsymbol{v}_{j}\\circledast\\boldsymbol{x}_{t}\\right)^{T}+\\Lambda_u.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling latent factors $\\boldsymbol{v}_{j},j\\in\\left\\{1,2,...,n\\right\\}$\n",
    "\n",
    "Draw $\\boldsymbol{v}_{j}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_j^{*},(\\Lambda_{j}^{*})^{-1}\\right)$ with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{j}^{*}=\\left(\\Lambda_{j}^{*}\\right)^{-1}\\left\\{\\tau\\sum_{i,t:(i,j,t)\\in\\Omega}y_{ijt}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)+\\Lambda_v\\boldsymbol{\\mu}_v\\right\\}$$\n",
    "\n",
    "$$\\Lambda_{j}^{*}=\\tau\\sum_{i,t:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{x}_{t}\\right)^{T}+\\Lambda_v.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling latent factors $\\boldsymbol{x}_{t},t\\in\\left\\{1,2,...,f\\right\\}$\n",
    "\n",
    "Draw $\\boldsymbol{x}_{t}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_t^{*},(\\Lambda_{t}^{*})^{-1}\\right)$ with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{t}^{*}=\\left(\\Lambda_{t}^{*}\\right)^{-1}\\left\\{\\tau\\sum_{i,j:(i,j,t)\\in\\Omega}y_{ijt}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)+\\Lambda_x\\boldsymbol{\\mu}_x\\right\\}$$\n",
    "\n",
    "$$\\Lambda_{t}^{*}=\\tau\\sum_{i,j:(i,j,t)\\in\\Omega}\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)\\left(\\boldsymbol{u}_{i}\\circledast\\boldsymbol{v}_{j}\\right)^{T}+\\Lambda_x.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling precision term $\\tau$\n",
    "\n",
    "Draw $\\tau\\in\\text{Gamma}\\left(a^{*},b^{*}\\right)$ with following parameters:\n",
    "\n",
    "$$a^{*}=a_0+\\frac{1}{2}|\\Omega|,~b^{*}=b_0+\\frac{1}{2}\\sum_{(i,j,t)\\in\\Omega}\\left(y_{ijt}-\\sum_{s=1}^{r}u_{is}v_{js}x_{ts}\\right)^2.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling hyperparameters $\\left(\\boldsymbol{\\mu}_{u},\\Lambda_{u}\\right)$\n",
    "\n",
    "Draw\n",
    "\n",
    "- $\\Lambda_{u}\\sim\\mathcal{W}\\left(W_u^{*},\\nu_u^{*}\\right)$\n",
    "- $\\boldsymbol{\\mu}_{u}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{u}^{*},\\left(\\beta_u^{*}\\Lambda_u\\right)^{-1}\\right)$\n",
    "\n",
    "with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{u}^{*}=\\frac{m\\boldsymbol{\\bar{u}}+\\beta_0\\boldsymbol{\\mu}_0}{m+\\beta_0},~\\beta_u^{*}=m+\\beta_0,~\\nu_u^{*}=m+\\nu_0,$$\n",
    "$$\\left(W_u^{*}\\right)^{-1}=W_0^{-1}+mS_u+\\frac{m\\beta_0}{m+\\beta_0}\\left(\\boldsymbol{\\bar{u}}-\\boldsymbol{\\mu}_0\\right)\\left(\\boldsymbol{\\bar{u}}-\\boldsymbol{\\mu}_0\\right)^T,$$\n",
    "where $\\boldsymbol{\\bar{u}}=\\sum_{i=1}^{m}\\boldsymbol{u}_{i},~S_u=\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\boldsymbol{u}_{i}-\\boldsymbol{\\bar{u}}\\right)\\left(\\boldsymbol{u}_{i}-\\boldsymbol{\\bar{u}}\\right)^T$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling hyperparameters $\\left(\\boldsymbol{\\mu}_{v},\\Lambda_{v}\\right)$\n",
    "\n",
    "Draw\n",
    "\n",
    "- $\\Lambda_{v}\\sim\\mathcal{W}\\left(W_v^{*},\\nu_v^{*}\\right)$\n",
    "- $\\boldsymbol{\\mu}_{v}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{v}^{*},\\left(\\beta_v^{*}\\Lambda_v\\right)^{-1}\\right)$\n",
    "\n",
    "with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{v}^{*}=\\frac{n\\boldsymbol{\\bar{v}}+\\beta_0\\boldsymbol{\\mu}_0}{n+\\beta_0},~\\beta_v^{*}=n+\\beta_0,~\\nu_v^{*}=n+\\nu_0,$$\n",
    "$$\\left(W_v^{*}\\right)^{-1}=W_0^{-1}+nS_v+\\frac{n\\beta_0}{n+\\beta_0}\\left(\\boldsymbol{\\bar{v}}-\\boldsymbol{\\mu}_0\\right)\\left(\\boldsymbol{\\bar{v}}-\\boldsymbol{\\mu}_0\\right)^T,$$\n",
    "where $\\boldsymbol{\\bar{v}}=\\sum_{j=1}^{n}\\boldsymbol{v}_{j},~S_v=\\frac{1}{n}\\sum_{j=1}^{n}\\left(\\boldsymbol{v}_{j}-\\boldsymbol{\\bar{v}}\\right)\\left(\\boldsymbol{v}_{j}-\\boldsymbol{\\bar{v}}\\right)^T$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sampling hyperparameters $\\left(\\boldsymbol{\\mu}_{x},\\Lambda_{x}\\right)$\n",
    "\n",
    "Draw\n",
    "\n",
    "- $\\Lambda_{x}\\sim\\mathcal{W}\\left(W_x^{*},\\nu_x^{*}\\right)$\n",
    "- $\\boldsymbol{\\mu}_{x}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{x}^{*},\\left(\\beta_x^{*}\\Lambda_x\\right)^{-1}\\right)$\n",
    "\n",
    "with following parameters:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{x}^{*}=\\frac{f\\boldsymbol{\\bar{x}}+\\beta_0\\boldsymbol{\\mu}_0}{f+\\beta_0},~\\beta_x^{*}=f+\\beta_0,~\\nu_x^{*}=f+\\nu_0,$$\n",
    "$$\\left(W_x^{*}\\right)^{-1}=W_0^{-1}+fS_x+\\frac{f\\beta_0}{f+\\beta_0}\\left(\\boldsymbol{\\bar{x}}-\\boldsymbol{\\mu}_0\\right)\\left(\\boldsymbol{\\bar{x}}-\\boldsymbol{\\mu}_0\\right)^T,$$\n",
    "where $\\boldsymbol{\\bar{x}}=\\sum_{t=1}^{f}\\boldsymbol{x}_{t},~S_x=\\frac{1}{f}\\sum_{t=1}^{f}\\left(\\boldsymbol{x}_{t}-\\boldsymbol{\\bar{x}}\\right)\\left(\\boldsymbol{x}_{t}-\\boldsymbol{\\bar{x}}\\right)^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:23.555598Z",
     "start_time": "2020-11-07T08:24:23.532621Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_factor(tau_sparse_tensor, tau_ind, factor, k, beta0 = 1):\n",
    "    dim, rank = factor[k].shape\n",
    "    dim = factor[k].shape[0]\n",
    "    factor_bar = np.mean(factor[k], axis = 0)\n",
    "    temp = dim / (dim + beta0)\n",
    "    var_mu_hyper = temp * factor_bar\n",
    "    var_W_hyper = inv(np.eye(rank) + cov_mat(factor[k], factor_bar) + temp * beta0 * np.outer(factor_bar, factor_bar))\n",
    "    var_Lambda_hyper = wishart.rvs(df = dim + rank, scale = var_W_hyper)\n",
    "    var_mu_hyper = mvnrnd_pre(var_mu_hyper, (dim + beta0) * var_Lambda_hyper)\n",
    "    \n",
    "    if k == 0:\n",
    "        var1 = kr_prod(factor[k + 2], factor[k + 1]).T\n",
    "    elif k == 1:\n",
    "        var1 = kr_prod(factor[k + 1], factor[k - 1]).T\n",
    "    elif k == 2:\n",
    "        var1 = kr_prod(factor[k - 1], factor[k - 2]).T\n",
    "    var2 = kr_prod(var1, var1)\n",
    "    var3 = (var2 @ ten2mat(tau_ind, k).T).reshape([rank, rank, dim]) + var_Lambda_hyper[:, :, np.newaxis]\n",
    "    var4 = var1 @ ten2mat(tau_sparse_tensor, k).T + (var_Lambda_hyper @ var_mu_hyper)[:, np.newaxis]\n",
    "    for i in range(dim):\n",
    "        factor[k][i, :] = mvnrnd_pre(solve(var3[:, :, i], var4[:, i]), var3[:, :, i])\n",
    "    return factor[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:24.907627Z",
     "start_time": "2020-11-07T08:24:24.896593Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_precision_tau(sparse_tensor, tensor_hat, ind):\n",
    "    var_alpha = 1e-6 + 0.5 * np.sum(ind)\n",
    "    var_beta = 1e-6 + 0.5 * np.sum(((sparse_tensor - tensor_hat) ** 2) * ind)\n",
    "    return np.random.gamma(var_alpha, 1 / var_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Performance Metrics\n",
    "\n",
    "- **RMSE**\n",
    "- **MAPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:26.908589Z",
     "start_time": "2020-11-07T08:24:26.889595Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define BGCP with `Numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:24:29.999591Z",
     "start_time": "2020-11-07T08:24:29.979623Z"
    }
   },
   "outputs": [],
   "source": [
    "def BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter):\n",
    "    \"\"\"Bayesian Gaussian CP (BGCP) decomposition.\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    rank = factor[0].shape[1]\n",
    "    if np.isnan(sparse_tensor).any() == False:\n",
    "        ind = sparse_tensor != 0\n",
    "        pos_obs = np.where(ind)\n",
    "        pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    elif np.isnan(sparse_tensor).any() == True:\n",
    "        pos_test = np.where((dense_tensor != 0) & (np.isnan(sparse_tensor)))\n",
    "        ind = ~np.isnan(sparse_tensor)\n",
    "        pos_obs = np.where(ind)\n",
    "        sparse_tensor[np.isnan(sparse_tensor)] = 0\n",
    "    show_iter = 200\n",
    "    tau = 1\n",
    "    factor_plus = []\n",
    "    for k in range(len(dim)):\n",
    "        factor_plus.append(np.zeros((dim[k], rank)))\n",
    "    temp_hat = np.zeros(sparse_tensor.shape)\n",
    "    tensor_hat_plus = np.zeros(dim)\n",
    "    for it in range(burn_iter + gibbs_iter):\n",
    "        tau_ind = tau * ind\n",
    "        tau_sparse_tensor = tau * sparse_tensor\n",
    "        for k in range(len(dim)):\n",
    "            factor[k] = sample_factor(tau_sparse_tensor, tau_ind, factor, k)\n",
    "        tensor_hat = cp_combine(factor)\n",
    "        temp_hat += tensor_hat\n",
    "        tau = sample_precision_tau(sparse_tensor, tensor_hat, ind)\n",
    "        if it + 1 > burn_iter:\n",
    "            factor_plus = [factor_plus[k] + factor[k] for k in range(len(dim))]\n",
    "            tensor_hat_plus += tensor_hat\n",
    "        if (it + 1) % show_iter == 0 and it < burn_iter:\n",
    "            temp_hat = temp_hat / show_iter\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], temp_hat[pos_test])))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], temp_hat[pos_test])))\n",
    "            temp_hat = np.zeros(sparse_tensor.shape)\n",
    "            print()\n",
    "    factor = [i / gibbs_iter for i in factor_plus]\n",
    "    tensor_hat = tensor_hat_plus / gibbs_iter\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print()\n",
    "    \n",
    "    return tensor_hat, factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments on PeMS-4W Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T08:25:05.840143Z",
     "start_time": "2020-11-07T08:24:33.389630Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_tensor = np.random.rand(data.values.shape[0], 288, 4 * 7)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T13:12:34.404526Z",
     "start_time": "2020-11-07T08:25:05.843145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0509573\n",
      "RMSE: 4.34123\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.050683\n",
      "RMSE: 4.33272\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0505847\n",
      "RMSE: 4.3285\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0504597\n",
      "RMSE: 4.32072\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0504452\n",
      "RMSE: 4.31881\n",
      "\n",
      "Imputation MAPE: 0.0502532\n",
      "Imputation RMSE: 4.31065\n",
      "\n",
      "Running time: 287.48 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T13:13:03.907523Z",
     "start_time": "2020-11-07T13:12:34.411524Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_tensor = np.random.rand(data.values.shape[0], 288, 4 * 7)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T17:59:09.426494Z",
     "start_time": "2020-11-07T13:13:03.909526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0508234\n",
      "RMSE: 4.3172\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0502252\n",
      "RMSE: 4.31527\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0502002\n",
      "RMSE: 4.31466\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0501868\n",
      "RMSE: 4.31439\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.050184\n",
      "RMSE: 4.31425\n",
      "\n",
      "Imputation MAPE: 0.0501825\n",
      "Imputation RMSE: 4.31415\n",
      "\n",
      "Running time: 286.09 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T17:59:34.326769Z",
     "start_time": "2020-11-07T17:59:09.429496Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_matrix = np.random.rand(data.values.shape[0], 4 * 7)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[2]):\n",
    "        binary_tensor[i1, :, i2] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:44:20.531318Z",
     "start_time": "2020-11-07T17:59:34.328770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0541532\n",
      "RMSE: 4.57425\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0540382\n",
      "RMSE: 4.5875\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0539228\n",
      "RMSE: 4.58336\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0538353\n",
      "RMSE: 4.58434\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0538185\n",
      "RMSE: 4.58871\n",
      "\n",
      "Imputation MAPE: 0.0537746\n",
      "Imputation RMSE: 4.59074\n",
      "\n",
      "Running time: 284.77 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:52:12.075014Z",
     "start_time": "2020-11-08T01:51:44.656016Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_matrix = np.random.rand(data.values.shape[0], 4 * 7)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[2]):\n",
    "        binary_tensor[i1, :, i2] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T06:37:16.895636Z",
     "start_time": "2020-11-08T01:52:12.078017Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0599587\n",
      "RMSE: 5.07417\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0609349\n",
      "RMSE: 5.40117\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0606259\n",
      "RMSE: 5.40451\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0608938\n",
      "RMSE: 5.46919\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0610082\n",
      "RMSE: 5.49707\n",
      "\n",
      "Imputation MAPE: 0.0610061\n",
      "Imputation RMSE: 5.49654\n",
      "\n",
      "Running time: 285.08 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start)/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments on PeMS-8W Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T06:38:45.171633Z",
     "start_time": "2020-11-08T06:37:16.907635Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-8w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 8 * 7]), 0)\n",
    "random_tensor = np.random.rand(data.values.shape[0], 288, 8 * 7)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:21.223608Z",
     "start_time": "2020-11-08T06:38:45.174636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0536342\n",
      "RMSE: 4.54811\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0528521\n",
      "RMSE: 4.51873\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0528394\n",
      "RMSE: 4.51789\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.052841\n",
      "RMSE: 4.51758\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0528411\n",
      "RMSE: 4.51738\n",
      "\n",
      "Imputation MAPE: 0.0528409\n",
      "Imputation RMSE: 4.51715\n",
      "\n",
      "Running time: 585.60 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:25:49.278732Z",
     "start_time": "2020-11-08T16:24:21.230608Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-8w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 8 * 7]), 0)\n",
    "random_tensor = np.random.rand(data.values.shape[0], 288, 8 * 7)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:39:42.040091Z",
     "start_time": "2020-11-08T16:25:49.280721Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0532732\n",
      "RMSE: 4.52602\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0527793\n",
      "RMSE: 4.51802\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0527547\n",
      "RMSE: 4.51666\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0527249\n",
      "RMSE: 4.51404\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0527285\n",
      "RMSE: 4.51299\n",
      "\n",
      "Imputation MAPE: 0.0527291\n",
      "Imputation RMSE: 4.5127\n",
      "\n",
      "Running time: 553.88 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T01:41:06.730092Z",
     "start_time": "2020-11-09T01:39:42.049092Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-8w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 8 * 7]), 0)\n",
    "random_matrix = np.random.rand(data.values.shape[0], 8 * 7)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[2]):\n",
    "        binary_tensor[i1, :, i2] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T11:04:32.018435Z",
     "start_time": "2020-11-09T01:41:06.733093Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0559252\n",
      "RMSE: 4.69442\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0551243\n",
      "RMSE: 4.67289\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0548693\n",
      "RMSE: 4.66503\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0547806\n",
      "RMSE: 4.66047\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0547388\n",
      "RMSE: 4.65913\n",
      "\n",
      "Imputation MAPE: 0.0547163\n",
      "Imputation RMSE: 4.65863\n",
      "\n",
      "Running time: 563.42 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T11:05:51.217433Z",
     "start_time": "2020-11-09T11:04:32.025436Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-8w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 8 * 7]), 0)\n",
    "random_matrix = np.random.rand(data.values.shape[0], 8 * 7)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[2]):\n",
    "        binary_tensor[i1, :, i2] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T20:17:09.566807Z",
     "start_time": "2020-11-09T11:05:51.219445Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0573149\n",
      "RMSE: 4.81128\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0562119\n",
      "RMSE: 4.77796\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0562737\n",
      "RMSE: 4.80638\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.056286\n",
      "RMSE: 4.81353\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0563006\n",
      "RMSE: 4.81698\n",
      "\n",
      "Imputation MAPE: 0.0563073\n",
      "Imputation RMSE: 4.81831\n",
      "\n",
      "Running time: 551.31 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start)/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments on London-1M Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 30, 24])\n",
    "sparse_tensor = sparse_mat.reshape([sparse_mat.shape[0], 30, 24])\n",
    "del dense_mat, sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0922696\n",
      "RMSE: 2.2483\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0920824\n",
      "RMSE: 2.24374\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.092008\n",
      "RMSE: 2.24153\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0919649\n",
      "RMSE: 2.23992\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0918846\n",
      "RMSE: 2.23833\n",
      "\n",
      "Imputation MAPE: 0.0918061\n",
      "Imputation RMSE: 2.23727\n",
      "\n",
      "Running time: 12058 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 30, 24])\n",
    "sparse_tensor = sparse_mat.reshape([sparse_mat.shape[0], 30, 24])\n",
    "del dense_mat, sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.094615\n",
      "RMSE: 2.3016\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0946033\n",
      "RMSE: 2.30029\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0945642\n",
      "RMSE: 2.29905\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0945298\n",
      "RMSE: 2.29797\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.094502\n",
      "RMSE: 2.29739\n",
      "\n",
      "Imputation MAPE: 0.0944727\n",
      "Imputation RMSE: 2.29685\n",
      "\n",
      "Running time: 11992 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_mat = np.zeros(dense_mat.shape)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], 30)\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(30):\n",
    "        binary_mat[i1, i2 * 24 : (i2 + 1) * 24] = np.round(random_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 30, 24])\n",
    "sparse_tensor = sparse_mat.reshape([sparse_mat.shape[0], 30, 24])\n",
    "del dense_mat, sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0944617\n",
      "RMSE: 2.30578\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0946107\n",
      "RMSE: 2.31102\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0946036\n",
      "RMSE: 2.31093\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0945849\n",
      "RMSE: 2.31061\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0945564\n",
      "RMSE: 2.31009\n",
      "\n",
      "Imputation MAPE: 0.0945378\n",
      "Imputation RMSE: 2.30959\n",
      "\n",
      "Running time: 11473 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_mat = np.zeros(dense_mat.shape)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], 30)\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(30):\n",
    "        binary_mat[i1, i2 * 24 : (i2 + 1) * 24] = np.round(random_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "dense_tensor = dense_mat.reshape([dense_mat.shape[0], 30, 24])\n",
    "sparse_tensor = sparse_mat.reshape([sparse_mat.shape[0], 30, 24])\n",
    "del dense_mat, sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.09921\n",
      "RMSE: 2.42329\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0999265\n",
      "RMSE: 2.44132\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0999539\n",
      "RMSE: 2.44186\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.09997\n",
      "RMSE: 2.44213\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0999865\n",
      "RMSE: 2.44243\n",
      "\n",
      "Imputation MAPE: 0.0999842\n",
      "Imputation RMSE: 2.44213\n",
      "\n",
      "Running time: 12733 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 20\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments on Guangzhou-2M Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "missing_rate = 0.3\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0839745\n",
      "RMSE: 3.61647\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0835623\n",
      "RMSE: 3.60507\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0833741\n",
      "RMSE: 3.59895\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0832037\n",
      "RMSE: 3.59308\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.083074\n",
      "RMSE: 3.58745\n",
      "\n",
      "Imputation MAPE: 0.0829904\n",
      "Imputation RMSE: 3.58367\n",
      "\n",
      "Running time: 3108 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 80\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "missing_rate = 0.7\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0864222\n",
      "RMSE: 3.72361\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0860259\n",
      "RMSE: 3.71598\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0857265\n",
      "RMSE: 3.70482\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.085522\n",
      "RMSE: 3.69766\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0853367\n",
      "RMSE: 3.69149\n",
      "\n",
      "Imputation MAPE: 0.0853178\n",
      "Imputation RMSE: 3.68971\n",
      "\n",
      "Running time: 3133 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 80\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')['random_matrix']\n",
    "missing_rate = 0.3\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.101898\n",
      "RMSE: 4.2785\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.102387\n",
      "RMSE: 4.3103\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.102448\n",
      "RMSE: 4.31487\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.102476\n",
      "RMSE: 4.31679\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102471\n",
      "RMSE: 4.31745\n",
      "\n",
      "Imputation MAPE: 0.102478\n",
      "Imputation RMSE: 4.31969\n",
      "\n",
      "Running time: 159 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 10\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')['random_matrix']\n",
    "missing_rate = 0.7\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.113098\n",
      "RMSE: 4.63985\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.113084\n",
      "RMSE: 4.65119\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.112895\n",
      "RMSE: 4.64176\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.112743\n",
      "RMSE: 4.6363\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.112747\n",
      "RMSE: 4.6376\n",
      "\n",
      "Imputation MAPE: 0.112771\n",
      "Imputation RMSE: 4.63918\n",
      "\n",
      "Running time: 129 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 5\n",
    "factor = []\n",
    "for k in range(len(dim)):\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
